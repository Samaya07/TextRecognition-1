{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e9bffaf-69a7-4ea1-a57e-05858d481951",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd5af1d4-5ce7-47d8-8a18-c5392644f1c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Milly</td>\n",
       "      <td>B-BRAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>24</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>SLICES</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>CHEESE</td>\n",
       "      <td>B-PRODUCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>SLICES</td>\n",
       "      <td>I-PRODUCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #    Word        Tag\n",
       "0  Sentence: 1   Milly    B-BRAND\n",
       "1  Sentence: 1      24          O\n",
       "2  Sentence: 1  SLICES          O\n",
       "3  Sentence: 1  CHEESE  B-PRODUCT\n",
       "4  Sentence: 1  SLICES  I-PRODUCT"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../NER_Products_model/WordNER.csv\"\n",
    "\n",
    "data = pd.read_csv(data_path, encoding= 'unicode_escape')\n",
    "\n",
    "# data.fillna(method = 'ffill', inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6ff491a-44bb-4721-ae55-0dc05b750d3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Milly 24 SLICES CHEESE SLICES Net Weight : 480...</td>\n",
       "      <td>['B-BRAND', 'O', 'O', 'B-PRODUCT', 'I-PRODUCT'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>SPICED BUTTERMILK 9.00 Ne l 26 ) 2pcs Amu . ( ...</td>\n",
       "      <td>['B-PRODUCT', 'I-PRODUCT', 'O', 'O', 'O', 'O',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 3</td>\n",
       "      <td>Partly Skimmed Fruit Yogurt epigamia eplgmia 1...</td>\n",
       "      <td>['O', 'O', 'O', 'B-PRODUCT', 'B-BRAND', 'O', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 4</td>\n",
       "      <td>modeRn moder DeRn Omilk plus bread W 's Co pac...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'B-PRODUCT', 'O', 'O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 5</td>\n",
       "      <td>BAREVR 2 iDY PANEER SOFT &amp; CREAMYC FROM NATURA...</td>\n",
       "      <td>['O', 'O', 'B-BRAND', 'B-PRODUCT', 'O', 'O', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #                                           Sentence  \\\n",
       "0  Sentence: 1  Milly 24 SLICES CHEESE SLICES Net Weight : 480...   \n",
       "1  Sentence: 2  SPICED BUTTERMILK 9.00 Ne l 26 ) 2pcs Amu . ( ...   \n",
       "2  Sentence: 3  Partly Skimmed Fruit Yogurt epigamia eplgmia 1...   \n",
       "3  Sentence: 4  modeRn moder DeRn Omilk plus bread W 's Co pac...   \n",
       "4  Sentence: 5  BAREVR 2 iDY PANEER SOFT & CREAMYC FROM NATURA...   \n",
       "\n",
       "                                                 Tag  \n",
       "0  ['B-BRAND', 'O', 'O', 'B-PRODUCT', 'I-PRODUCT'...  \n",
       "1  ['B-PRODUCT', 'I-PRODUCT', 'O', 'O', 'O', 'O',...  \n",
       "2  ['O', 'O', 'O', 'B-PRODUCT', 'B-BRAND', 'O', '...  \n",
       "3  ['O', 'O', 'O', 'O', 'O', 'B-PRODUCT', 'O', 'O...  \n",
       "4  ['O', 'O', 'B-BRAND', 'B-PRODUCT', 'O', 'O', '...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ready_dist_path = \"../NER_Products_model/SentenceNER.csv\"\n",
    "ready_data = pd.read_csv(ready_dist_path)\n",
    "ready_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f1d1f25-ae91-4171-9a6c-15968713e2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def join_a_sentence(sentence_number):\n",
    "    \n",
    "    sentence_number = str(sentence_number)\n",
    "    the_sentence_words_list = list(data[data['Sentence #'] == 'Sentence: {}'.format(sentence_number)]['Word'])\n",
    "    \n",
    "    return ' '.join(the_sentence_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c9ea33-1201-487f-b370-4c9b5441e990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Milly 24 SLICES CHEESE SLICES Net Weight : 480 g 0.53 KB / S \" Suggested Serving ony 26'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_a_sentence(sentence_number = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf4f94ee-387a-452a-8c28-4b0ea0496be4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B-BRAND', 'O', 'B-PRODUCT', 'I-PRODUCT', 'I-BRAND', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = data.Tag.unique()\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6148f784-f3a0-4787-a090-560eea82fd66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-BRAND': 101,\n",
       " 'O': 3393,\n",
       " 'B-PRODUCT': 110,\n",
       " 'I-PRODUCT': 87,\n",
       " 'I-BRAND': 28,\n",
       " nan: 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def num_words_tags (tags, data):\n",
    "    \n",
    "    tags_count = {}\n",
    "    \n",
    "    for tag in tags:\n",
    "        len_tag = len(data[data['Tag'] == tag])\n",
    "        tags_count[tag] = len_tag\n",
    "    \n",
    "    return tags_count\n",
    "\n",
    "tags_count = num_words_tags(tags, data)\n",
    "tags_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91c08325-160a-4074-925e-a7d11d9d45a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = list(ready_data['Sentence'])\n",
    "Y = list(ready_data['Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "382c8069-337c-4e99-ab5d-54ee1cc6af4d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      ['B-BRAND', 'O', 'O', 'B-PRODUCT', 'I-PRODUCT'...\n",
      "1      ['B-PRODUCT', 'I-PRODUCT', 'O', 'O', 'O', 'O',...\n",
      "2      ['O', 'O', 'O', 'B-PRODUCT', 'B-BRAND', 'O', '...\n",
      "3      ['O', 'O', 'O', 'O', 'O', 'B-PRODUCT', 'O', 'O...\n",
      "4      ['O', 'O', 'B-BRAND', 'B-PRODUCT', 'O', 'O', '...\n",
      "                             ...                        \n",
      "110    ['B-BRAND', 'O', 'B-PRODUCT', 'I-PRODUCT', 'O'...\n",
      "111    ['B-PRODUCT', 'I-PRODUCT', 'O', 'O', 'O', 'O',...\n",
      "112    ['O', 'O', 'O', 'B-PRODUCT', 'B-BRAND', 'O', '...\n",
      "113    ['B-BRAND', 'O', 'O', 'O', 'O', 'O', 'O', 'O',...\n",
      "114    ['O', 'O', 'B-BRAND', 'B-PRODUCT', 'O', 'O', '...\n",
      "Name: Tag, Length: 115, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ready_data['Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdd812fd-9582-476a-b673-4db31a57c26d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B-BRAND', 'O', 'O', 'B-PRODUCT', 'I-PRODUCT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PRODUCT', 'I-PRODUCT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-BRAND', 'I-BRAND', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'B-PRODUCT', 'B-BRAND', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n"
     ]
    }
   ],
   "source": [
    "Y_ready = []\n",
    "for sen_tags in Y:\n",
    "    # Handle missing values (replace with your preferred approach)\n",
    "    if sen_tags == 'nan':\n",
    "        Y_ready.append([])\n",
    "        continue\n",
    "\n",
    "    # Remove leading/trailing characters (if needed)\n",
    "    clean_str = sen_tags[1:-1]  # Assuming quotes enclose the list\n",
    "\n",
    "    # Check if the string is empty after cleaning (potential missing value)\n",
    "    if not clean_str:\n",
    "        Y_ready.append([])  # Append an empty list for empty strings\n",
    "        continue\n",
    "\n",
    "    # Split by delimiter (comma in this case)\n",
    "    tag_list = clean_str.split(',')\n",
    "\n",
    "    # Remove quotes or leading/trailing spaces from individual tags (if needed)\n",
    "    tag_list = [tag.strip()[1:-1] if len(tag) > 2 else tag.strip() for tag in tag_list]\n",
    "\n",
    "    Y_ready.append(tag_list)\n",
    "\n",
    "print(Y_ready[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bb12ec2-a51b-4bad-b36f-8eb6a171d5df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-BRAND': 0, 'O': 1, 'B-PRODUCT': 2, 'I-PRODUCT': 3, 'I-BRAND': 4, nan: 5}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id = {k: v for v, k in enumerate(data.Tag.unique())}\n",
    "id2label = {v: k for v, k in enumerate(data.Tag.unique())}\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66b40e79-4cec-4ddc-8fa9-9f11b7fd48f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24daa20-6466-4580-b83f-53d636828534",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcf9a9a2-832c-477c-8e1c-70a54466b0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# pad_token = tokenizer.pad_token \n",
    "\n",
    "# def prepare_data(sentences, tags, max_len=50):\n",
    "#   tokenized_sentences = []\n",
    "#   attention_masks = []\n",
    "#   padded_labels = []\n",
    "\n",
    "#   # Loop through sentences and tags (using unpacking from zip)\n",
    "#   for sentence, tag_list in zip(sentences, tags):\n",
    "#     # Access the current tag for each sentence\n",
    "#     tag = tag_list[0]  # Assuming tags are single strings (adjust if they are lists)\n",
    "\n",
    "#     # Tokenize the sentence\n",
    "#     encoded_sentence = tokenizer(sentence, add_special_tokens=True, padding='max_length', truncation=True)\n",
    "\n",
    "#     # Extract token IDs, attention mask, and pad tags\n",
    "#     tokenized_sentences.append(encoded_sentence['input_ids'])\n",
    "#     attention_masks.append(encoded_sentence['attention_mask'])\n",
    "#     padded_labels.append([tag] + [pad_token] * (max_len - len(tag_list)))  # Pad shorter tag sequences\n",
    "\n",
    "#   # Convert lists to NumPy arrays\n",
    "#   tokenized_sentences = np.array(tokenized_sentences, dtype=np.int32)\n",
    "#   attention_masks = np.array(attention_masks, dtype=np.int32)\n",
    "#   labels = np.array(padded_labels, dtype=np.int32)  # Assuming numerical tag IDs\n",
    "\n",
    "#   return tokenized_sentences, attention_masks, labels\n",
    "\n",
    "# tokenized_sentences, attention_masks, labels = prepare_data(X, Y_ready)\n",
    "\n",
    "# # Now you have your data prepared for training your NER model with DistilBERT\n",
    "# print(f\"Tokenized sentences: {tokenized_sentences.shape}\")\n",
    "# print(f\"Attention masks: {attention_masks.shape}\")\n",
    "# print(f\"Labels: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a708df4-018e-4922-9ae9-d77f41f6f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
    "\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
    "\n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
